{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Rebinning and How to Use Dask\n",
    "\n",
    "## Fundamentals of Dask\n",
    "\n",
    "In this session we are going to use the example of rebinning VISP data to discuss how the Dask array backing the `Dataset` object works.\n",
    "Dask is a Python package for out-of-memory and parallel computation in Python, it provides an array-like object where data is only loaded and processed on demand.\n",
    "`Dataset` uses Dask to track the data arrays, which it stores in the `Dataset.data` attribute.\n",
    "\n",
    "To demonstrate this let's load our VISP dataset from yesterday, and slice it to a more manageable size again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "This Dask object behaves in many ways just like a numpy array.\n",
    "For instance, it can indexed and sliced in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "And it has many of the same methods for calculating useful properties of the data, such as `min()`, `max()`, `sum()`, etc.\n",
    "These are in fact just wrappers around the numpy functions themselves, so they behave in the same way.\n",
    "For example, to find the sum over the spatial dimensions of our cropped data to make a spectrum, we could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "What you will notice when you call these functions that they don't return a number as you would expect.\n",
    "Instead they give us a Dask array which represents the result of that calculation.\n",
    "This is because Dask delays the actual calculation of the value until you explicitly tell it to do it using the `compute()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "A benefit of this is that since the operations returns us another Dask array, we can do more calculations with that, and those are also delayed.\n",
    "This means that you can string together any number of calculations and only perform the costly step of getting the actual answer once.\n",
    "So if we want to find the location of the lowest value in this spectrum, we can do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "When performing these operations, Dask breaks up the array into chunks, and operations will generally be faster and use less memory when they require fewer chunks. \n",
    "In the case of a `Dataset`, these chunks are aligned with the files, so each chunk essentially consists of the array stored in one FITS file.\n",
    "In the future we may break down a FITS file into more chunks, so the whole array does not always have to be read.\n",
    "\n",
    "## Rebinning with `NDCube`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": [
     "keep-inputs"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "We are going to use the {obj}`ndcube.NDCube.rebin` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "This rebin method, can reduce the resolution of a dataset, *by integer numbers of pixels*.\n",
    "\n",
    "So if we wanted to combine 7 pixels along the slit dimension together we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Because we are using Dask, this hasn't actually done any computation yet, but is has reduced the size of the dask array.\n",
    "```\n",
    "\n",
    "Let's compare two spectra, one from the rebinned dataset and one from the original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "As one final example of rebin, let's rebin in both the rastering dimension and the slit.\n",
    "Let's rebin to bins of 10x10 pixels, to do this we will need to make the slit axis divisible by 10, so we crop it down by 5 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Rebinning in Parallel\n",
    "\n",
    "By default dask will parallelise operations as much as is possible, over the available cores in your machine.\n",
    "The Dask project also supports paralleising over the distributed compute such as HPC or cloud computing.\n",
    "For this next section we are going to use this `distributed` package as a way of visualising the paralleisation.\n",
    "\n",
    "If you want to follow along with this bit you will need to install these packages, if you want to just watch that's also fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
