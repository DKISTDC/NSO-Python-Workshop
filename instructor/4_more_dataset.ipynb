{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12a80bea",
   "metadata": {},
   "source": [
    "# More Dataset\n",
    "\n",
    "Firstly we need to re-create our dataset object from the last notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1bae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dkist\n",
    "import dkist.net\n",
    "from sunpy.net import Fido, attrs as a\n",
    "\n",
    "res = Fido.search(a.dkist.Dataset('BEOGN'))\n",
    "files = Fido.fetch(res)\n",
    "ds = dkist.Dataset.from_asdf(files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1580fbc4",
   "metadata": {},
   "source": [
    "The `Dataset` object allows us to do some basic inspection of the dataset as a whole without having to download the entire thing, using the metadata in the FITS headers.\n",
    "This will save you a good amount of time and also ease the load on the DKIST servers.\n",
    "For example, we can check the seeing conditions during the observation.\n",
    "\n",
    "Notice that the file we have downloaded is a single ASDF file, **not** the whole dataset.\n",
    "We can use this file to construct the `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4dd6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will need this\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ds = dkist.Dataset.from_asdf(files[0])\n",
    "\n",
    "# This may be useful here\n",
    "ds.meta['inventory']['headerDocumentationUrl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82293462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just look at the headers for Stokes I so there aren't 4 lots of the same values\n",
    "I_headers = ds.headers[ds.headers['DINDEX4'] == 1]\n",
    "plt.plot(I_headers['ATMOS_R0'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4478c1c3",
   "metadata": {},
   "source": [
    "This information allows us to select the parts of the data where the seeing is good, and only download those files.\n",
    "We will see a more detailed demonstration of how to do this later.\n",
    "\n",
    "There is an important point to note about slicing the array to reduce the number of files, which is that you need to keep in mind how the data are stored across those files.\n",
    "We can see a little more information about the files with the `files` attribute of the `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc8620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042a4622",
   "metadata": {},
   "source": [
    "So in this case we can see that each FITS file contains effectively a 2D image - a single raster scan at one polarisation state - and that we have 4000 of these files to make a full 4D dataset.\n",
    "What this means is that if we look at a subset of the scan steps or polarisation states, we will reduce the number of files across which the array is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0321c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436e3af7",
   "metadata": {},
   "source": [
    "First, notice that when we slice a `Dataset` like this, the output we get here shows us not just the updated array shape but also the updated dimensions.\n",
    "Because we're looking at a single polarisation state, that axis and the corresponding physical axis have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eabf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[0].files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dd7376",
   "metadata": {},
   "source": [
    "However, if we decide we want to look at a single wavelength, we are taking a row of pixels from every single file.\n",
    "So although we reduce the dimensions of the array, we are not reducing the number of files we need to reference - and therefore download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f86e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[:, :, 500, :].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f90e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[:, :, 500, :].files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fa4215",
   "metadata": {},
   "source": [
    "## Downloading the quality report and preview movie\n",
    "\n",
    "For each dataset a quality report is produced during calibration which gives useful information about the quality of the data.\n",
    "This is accessible through the `Dataset`'s `quality_report()` method, which will download a PDF of the quality report to the base path of the dataset.\n",
    "This uses parfive underneath, which is the same library `Fido` uses, so it will return the same kind of `results` object.\n",
    "If the download has been successful, this can be treated as a list of filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b2e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "qr = ds.files.quality_report()\n",
    "qr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718952d6",
   "metadata": {},
   "source": [
    "This method takes the optional arguments `path` and `overwrite`.\n",
    "`path` allows you to specify a different location for the download, and `overwrite` is a boolean which tells the method whether or not to download a new copy if the file already exists.\n",
    "\n",
    "Similarly, each dataset also has a short preview movie showing the data.\n",
    "This can be downloaded in exactly the same way as the quality report but using the `preview_movie()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c5705",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = ds.files.preview_movie()\n",
    "pm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
